{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d56e41e4",
   "metadata": {},
   "source": [
    "# Anomaly Detection - Coding Exercise\n",
    "\n",
    "In this coding exercise, you will explore how unsupervised deep learning can be used to detect anomalies. The anomalies are simulated in form of out-of-distribution samples in a set of medical images. Two types of neural networks - an autoencoder and a variational autoencoder - will be implemented to detect these outliers without having access to examples of the anomalies during training.\n",
    "\n",
    "Authors: Felix Meissen and Martin Menten \n",
    "\n",
    "[Chair for AI in Medicine at TU Munich](http://aim-lab.io)\n",
    "\n",
    "For questions, please contact [felix.meissen@tum.de](mailto:felix.meissen@tum.de)\n",
    "\n",
    "Munich, 18.11.2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1346a638",
   "metadata": {},
   "source": [
    "### Set up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git init\n",
    "! git remote add origin https://github.com/martinmenten/anomaly-detection-tutorial.git\n",
    "! git fetch\n",
    "! git checkout -t origin/main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1346a638",
   "metadata": {},
   "source": [
    "### Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4df9921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from warnings import warn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mednist import (\n",
    "    MEDNISTDIR,\n",
    "    download_mednist,\n",
    "    get_anomal_files,\n",
    "    get_normal_files,\n",
    "    MedNISTDataset,\n",
    "    MedNISTTestDataset\n",
    ")\n",
    "from models import Autoencoder, VAE\n",
    "from utils import plot, plot_anomaly_scores\n",
    "\n",
    "# Select device to train on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cpu':\n",
    "    warn('No GPU found, training will be slow on CPU')\n",
    "\n",
    "# Config\n",
    "config = Namespace()\n",
    "config.batch_size = 128\n",
    "config.val_split = 0.8\n",
    "config.test_split = 0.9\n",
    "config.device = device\n",
    "\n",
    "# Reproducibility\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Autoreload modules without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e3764",
   "metadata": {},
   "source": [
    "### Download MedNIST and create DataLoader\n",
    "\n",
    "For this exercise, we will use the [MedNIST](https://medmnist.com) dataset [1,2]. The first cell below downloads parts of the the dataset and prepares training, validation and testing datasets and dataloaders. We define hand x-ray scans as our \"normal samples\" and create training and validation datasets that consist entirely of such x-rays. The test images, however, are evenly split between hand x-rays and anomal medical images, such as mammographs, chest x-rays as well as head, chest and abdominal computed tomography images. By running the second cell, samples from each dataset are presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download if necessary\n",
    "download_mednist(MEDNISTDIR)\n",
    "\n",
    "# Get all HeadCT and Hand files\n",
    "normal_files = get_normal_files(MEDNISTDIR, normal_class='Hand')\n",
    "anomal_files = get_anomal_files(MEDNISTDIR, normal_class='Hand')\n",
    "random.shuffle(anomal_files)  # Were sorted by class before\n",
    "anomal_files = anomal_files[:len(normal_files)]  # Assure number of files are equal\n",
    "\n",
    "# Create a training / validation / test split\n",
    "val_split_idx = int(len(normal_files) * config.val_split)\n",
    "test_split_idx = int(len(normal_files) * config.test_split)\n",
    "\n",
    "# Take 80% normal images for training\n",
    "train_files = normal_files[:val_split_idx]\n",
    "\n",
    "# Take 10% normal images for validation\n",
    "val_files = normal_files[val_split_idx:test_split_idx]\n",
    "\n",
    "# Take 10% normal images and an equal amount of anomal images\n",
    "test_files_1 = normal_files[test_split_idx:]\n",
    "test_files_2 = anomal_files[test_split_idx:]\n",
    "test_labels_1 = [0 for _ in range(len(test_files_1))]  # normal files are in-distribution -> 0\n",
    "test_labels_2 = [1 for _ in range(len(test_files_2))]  # anomal files are out-of-distribution -> 1\n",
    "test_files = test_files_1 + test_files_2\n",
    "test_labels = test_labels_1 + test_labels_2\n",
    "\n",
    "# Create a training dataset with normal files\n",
    "train_ds = MedNISTDataset(train_files)\n",
    "trainloader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "# Create a validation dataset with normal files\n",
    "val_ds = MedNISTDataset(val_files)\n",
    "valloader = DataLoader(val_ds, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "# Create a test dataset with normal and anomal files\n",
    "test_ds = MedNISTTestDataset(test_files, test_labels)\n",
    "testloader = DataLoader(test_ds, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "print('Training dataset size:', len(train_ds))\n",
    "print('Validation dataset size:', len(val_ds))\n",
    "print('Test dataset size:', len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566de8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!for f in ls ./data/MedNIST/*; do echo $f; ls $f | wc -l; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83270ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training images')\n",
    "plot([img for img in next(iter(trainloader))[:10, 0]])\n",
    "print('Validation images')\n",
    "plot([img for img in next(iter(valloader))[:10, 0]])\n",
    "print('Test images')\n",
    "imgs, labels = next(iter(testloader))\n",
    "labels = [\"Normal\" if label == 0 else \"Anomal\" for label in labels]\n",
    "plot([img for img in imgs[:10, 0]], titles=labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a58c39f",
   "metadata": {},
   "source": [
    "### Autoencoder\n",
    "\n",
    "The first anomaly detection strategy is based on a convolutional autoencoder. It consists of an encoder comprised of three convolutional blocks, a bottleneck and a decoder consisting of three convolutional blocks. The next two cells define the training procedure and train the Autoencoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9661eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder training functions\n",
    "\n",
    "def ae_train_step(ae, x, optimizer, device):\n",
    "    ae.train()\n",
    "    optimizer.zero_grad()\n",
    "    x = x.to(device)\n",
    "    x_recon = ae(x)\n",
    "    loss = ae.loss_function(x, x_recon)  # MSE loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ae_val_step(ae, x, device):\n",
    "    ae.eval()\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        x_recon = ae(x)\n",
    "    return ae.loss_function(x, x_recon).item(), x_recon\n",
    "\n",
    "\n",
    "def validate_ae(config, ae, valloader):\n",
    "    losses = []\n",
    "    for x in valloader:\n",
    "        loss, x_recon = ae_val_step(ae, x, config.device)\n",
    "        losses.append(loss)\n",
    "    return np.mean(losses), x.cpu(), x_recon.cpu()\n",
    "\n",
    "\n",
    "def train_ae(config, ae, optimizer, trainloader, valloader):\n",
    "    i_step = 0\n",
    "    i_epoch = 0\n",
    "    all_losses = []\n",
    "    losses = []\n",
    "    ae.train()\n",
    "    while True:\n",
    "        for x in trainloader:\n",
    "            # Train step\n",
    "            loss = ae_train_step(ae, x, optimizer, config.device)\n",
    "\n",
    "            # Store metrics\n",
    "            losses.append(loss)\n",
    "            all_losses.append(loss)\n",
    "\n",
    "            # Log\n",
    "            if i_step % config.log_frequency == 0:\n",
    "                print(f'Iteration {i_step} - train loss {np.mean(losses):.4f}')\n",
    "                losses = []\n",
    "\n",
    "            # Validate\n",
    "            if i_step % config.val_frequency == 0:\n",
    "                val_loss, x_val, x_recon = validate_ae(config, ae, valloader)\n",
    "                print(f'Iteration {i_step} - val loss {val_loss:.4f}')\n",
    "                residual = torch.abs(x_val - x_recon)\n",
    "                plot([x_val[0, 0], x_recon[0, 0], residual[0, 0]],\n",
    "                     titles=['input', 'reconstruction', 'residual'])\n",
    "\n",
    "            # Finish\n",
    "            i_step += 1\n",
    "            if i_step >= config.num_steps:\n",
    "                print('Finished training')\n",
    "                return ae, all_losses\n",
    "        i_epoch += 1\n",
    "        print(f'Finished epoch {i_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f361171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train config\n",
    "config.lr = 1e-3\n",
    "config.num_steps = 1000\n",
    "config.log_frequency = 50\n",
    "config.val_frequency = 100\n",
    "config.latent_dim = 128\n",
    "\n",
    "# Initialize Autoencoder\n",
    "ae = Autoencoder(latent_dim=config.latent_dim).to(device)\n",
    "#print(ae)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(ae.parameters(), lr=config.lr)\n",
    "\n",
    "# Train\n",
    "print('Start training...')\n",
    "ae, ae_loss_history = train_ae(config, ae, optimizer, trainloader, valloader)\n",
    "\n",
    "# Plot loss history\n",
    "plt.plot(ae_loss_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, 0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d87636",
   "metadata": {},
   "source": [
    "We test the Autoencoder on the test set defined above. For every sample, we use the mean absolute error of the input and the reconstructed image as anomaly score. We plot some examples with their reconstructions and the error maps and compute the area under the receiver operating characteristics curve (ROC AUC) to see how well our model can distinguish between in- and out-of-distribution samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a26c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "def ae_test_step(ae, x, device):\n",
    "    ae.eval()\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        x_recon = ae(x)\n",
    "    return x.cpu(), x_recon.cpu(), torch.abs(x - x_recon).cpu()\n",
    "\n",
    "def test_ae(config, ae, testloader):\n",
    "    scores = []\n",
    "    labels = []\n",
    "    ae.eval()\n",
    "    for x, y in testloader:\n",
    "        x, x_recon, residual = ae_test_step(ae, x, config.device)\n",
    "        anomaly_score = torch.mean(residual, dim=(1, 2, 3))\n",
    "        scores.extend(anomaly_score.numpy())\n",
    "        labels.extend(y.numpy())\n",
    "\n",
    "    # Plot a normal and anomalous test sample\n",
    "    if len(y == 0) > 0:\n",
    "        plot([x[y == 0][0, 0], x_recon[y == 0][0, 0], residual[y == 0][0, 0]],\n",
    "                titles=['input', 'reconstruction', 'residual'])\n",
    "    if len(y == 1) > 0:\n",
    "        plot([x[y == 1][0, 0], x_recon[y == 1][0, 0], residual[y == 1][0, 0]],\n",
    "                titles=['input', 'reconstruction', 'residual'])\n",
    "\n",
    "    return np.array(scores), np.array(labels)\n",
    "\n",
    "ae_scores, ae_labels = test_ae(config, ae, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "auroc = roc_auc_score(ae_labels, ae_scores)\n",
    "print(f'ROC AUC: {auroc:.4f}')\n",
    "\n",
    "plot_anomaly_scores(ae_scores, ae_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5d63a6",
   "metadata": {},
   "source": [
    "# Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36763a6",
   "metadata": {},
   "source": [
    "Our VAE has the same architecture as the Autoencoder, but doesn't directly compute the latent vector z in the bottleneck. Instead, it computes the mean and standard deviaton of a Gaussian distribution and samples z from it.\n",
    "Since it is not possible to backpropagate through a sampling step, we do the \"reparametrization trick\" as illustrated in the image. We sample from a unit gaussian $N(0,1)$ instead and scale and shift the value by $\\sigma$ and $\\mu$. This is equivalent to sampling directly from $N(\\mu,\\sigma)$.\n",
    "\n",
    "<img src=\"reparametrization_trick.png\" alt=\"reparametrization trick\" width=\"1300\"/>\n",
    "\n",
    "To train the VAE, we maximize the $ELBO$ (Evidence lower bound) which is a lower bound on the true log likelihood of the data $log\\:p(x)$. -> $ELBO \\leq log\\:p(x)$\n",
    "\n",
    "$ELBO = likelihood - KL$, where the reconstruction error can be modeled as the negative log likelihood.\n",
    "\n",
    "So to maximize $ELBO$ (and therefore also $p(x)$), we minimize the reconstruction error and the KL-divergence between $N(\\mu,\\sigma)$ and $N(0,1)$.\n",
    "\n",
    "For the derivation of the $ELBO$, have a look at:\n",
    "[https://fangdahan.medium.com/derivation-of-elbo-in-vae-25ad7991fdf7](https://fangdahan.medium.com/derivation-of-elbo-in-vae-25ad7991fdf7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE training functions\n",
    "\n",
    "def vae_train_step(vae, x, optimizer, device):\n",
    "    vae.train()\n",
    "    optimizer.zero_grad()\n",
    "    x = x.to(device)\n",
    "    x_recon, mu, logvar = vae(x)\n",
    "    loss_dict = vae.loss_function(x, x_recon, mu, logvar, kl_weight=2.0)  # VAE loss\n",
    "    loss = loss_dict['loss']\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss_dict\n",
    "\n",
    "\n",
    "def vae_val_step(vae, x, device):\n",
    "    vae.eval()\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        x_recon, mu, logvar = vae(x)\n",
    "    loss_dict = vae.loss_function(x, x_recon, mu, logvar, kl_weight=2.0)\n",
    "    return loss_dict, x_recon.cpu()\n",
    "\n",
    "\n",
    "def validate_vae(config, vae, valloader):\n",
    "    losses = defaultdict(list)\n",
    "    for x in valloader:\n",
    "        loss_dict, x_recon = vae_val_step(vae, x, config.device)\n",
    "        for k, v in loss_dict.items():\n",
    "            losses[k].append(v.item())\n",
    "    losses = {k: np.mean(v) for k, v in losses.items()}\n",
    "    return losses, x.cpu(), x_recon.cpu()\n",
    "\n",
    "\n",
    "def train_vae(config, vae, optimizer, trainloader, valloader):\n",
    "    i_step = 0\n",
    "    i_epoch = 0\n",
    "    all_losses = defaultdict(list)\n",
    "    losses = defaultdict(list)\n",
    "    vae.train()\n",
    "    while True:\n",
    "        for x in trainloader:\n",
    "            # Train step\n",
    "            loss_dict = vae_train_step(vae, x, optimizer, config.device)\n",
    "\n",
    "            # Store metrics\n",
    "            for k, v in loss_dict.items():\n",
    "                losses[k].append(v.item())\n",
    "                all_losses[k].append(v.item())\n",
    "\n",
    "            # Log\n",
    "            if i_step % config.log_frequency == 0:\n",
    "                losses = {k: np.mean(v) for k, v in losses.items()}\n",
    "                log_msg = f'Iteration {i_step}'\n",
    "                for k, v in losses.items():\n",
    "                    log_msg += f' - {k}: {v:.4f}'\n",
    "                print(log_msg)\n",
    "                losses = defaultdict(list)\n",
    "\n",
    "            # Validate\n",
    "            if i_step % config.val_frequency == 0:\n",
    "                val_losses, x_val, x_recon = validate_vae(config, vae, valloader)\n",
    "                log_msg = f'Iteration {i_step}'\n",
    "                for k, v in val_losses.items():\n",
    "                    log_msg += f' - val {k}: {v:.4f}'\n",
    "                print(log_msg)\n",
    "                residual = torch.abs(x_val - x_recon)\n",
    "                plot([x_val[0, 0], x_recon[0, 0], residual[0, 0]],\n",
    "                     titles=['input', 'reconstruction', 'residual'])\n",
    "\n",
    "            # Finish\n",
    "            i_step += 1\n",
    "            if i_step >= config.num_steps:\n",
    "                print('Finished training')\n",
    "                return vae, all_losses\n",
    "        i_epoch += 1\n",
    "        print(f'Finished epoch {i_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Variational Autoencoder\n",
    "vae = VAE(latent_dim=config.latent_dim).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=config.lr)\n",
    "\n",
    "# Train\n",
    "print('Start training...')\n",
    "vae, vae_loss_history = train_vae(config, vae, optimizer, trainloader, valloader)\n",
    "\n",
    "# Plot loss history\n",
    "for k, v in vae_loss_history.items():\n",
    "    plt.plot(v, label=k)\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, 0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3008688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing VAE\n",
    "\n",
    "def vae_test_step(vae, x, device):\n",
    "    vae.eval()\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        anomaly_scores = vae.anomaly_score(x)\n",
    "    return anomaly_scores.cpu()\n",
    "\n",
    "def test_vae(config, vae, testloader):\n",
    "    scores = []\n",
    "    labels = []\n",
    "    vae.eval()\n",
    "    for x, y in testloader:\n",
    "        anomaly_scores = vae_test_step(vae, x, config.device)\n",
    "        scores.extend(anomaly_scores.numpy())\n",
    "        labels.extend(y.numpy())\n",
    "\n",
    "    return np.array(scores), np.array(labels)\n",
    "\n",
    "vae_scores, vae_labels = test_vae(config, vae, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "auroc = roc_auc_score(vae_labels, vae_scores)\n",
    "print(f'ROC AUC: {auroc:.4f}')\n",
    "\n",
    "plot_anomaly_scores(vae_scores, vae_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970f558",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "With self-supervised methods we can perform tasks without the need for labels. Anomaly detection can even segment anomalous regions like tumors in an image. However, this is still ongoing research.\n",
    "In our experiments, the reconstruction-based method performed better, than the likelihood-based method. This is not always the case, using the reconstruction error as anomaly scoring function can have severe drawbacks in other cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94639c5e",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] Jiancheng Yang, Rui Shi, Donglai Wei, Zequan Liu, Lin Zhao, Bilian Ke, Hanspeter Pfister, Bingbing Ni. \"MedMNIST v2: A Large-Scale Lightweight Benchmark for 2D and 3D Biomedical Image Classification\". arXiv preprint arXiv:2110.14795, 2021.\n",
    "\n",
    "[2] Jiancheng Yang, Rui Shi, Bingbing Ni. \"MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for Medical Image Analysis\". IEEE 18th International Symposium on Biomedical Imaging (ISBI), 2021."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
