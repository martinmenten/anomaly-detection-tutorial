{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1346a638",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mednist import (\n",
    "    MEDNISTDIR,\n",
    "    download_mednist,\n",
    "    get_mednist_files,\n",
    "    MedNISTDataset,\n",
    "    MedNISTTestDataset\n",
    ")\n",
    "from models import Autoencoder\n",
    "from utils import plot\n",
    "\n",
    "# Select device to train on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Autoreload modules without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b816f6",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83101848",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Namespace()\n",
    "config.batch_size = 128\n",
    "config.val_split = 0.8\n",
    "config.test_split = 0.9\n",
    "config.device = device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e3764",
   "metadata": {},
   "source": [
    "## Download MedNIST and create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download if necessary\n",
    "download_mednist(MEDNISTDIR)\n",
    "\n",
    "# Get all HeadCT and Hand files\n",
    "head_ct_files = get_mednist_files(MEDNISTDIR, 'HeadCT')\n",
    "hand_files = get_mednist_files(MEDNISTDIR, 'Hand')\n",
    "\n",
    "# Create a training / validation / test split\n",
    "val_split_idx = int(len(head_ct_files) * config.val_split)\n",
    "test_split_idx = int(len(head_ct_files) * config.test_split)\n",
    "\n",
    "# Take 8000 HeadCT images for training\n",
    "train_files = head_ct_files[:val_split_idx]\n",
    "\n",
    "# Take 1000 HeadCT images for validation\n",
    "val_files = head_ct_files[val_split_idx:test_split_idx]\n",
    "\n",
    "test_files_1 = head_ct_files[test_split_idx:]  # Take 1000 headCT images\n",
    "test_files_2 = hand_files[test_split_idx:]  # And 1000 hand images for test\n",
    "test_labels_1 = [0 for _ in range(len(test_files_1))]  # HeadCT are in-distribution -> 0\n",
    "test_labels_2 = [1 for _ in range(len(test_files_2))]  # Hand are out-of-distribution -> 1\n",
    "test_files = test_files_1 + test_files_2\n",
    "test_labels = test_labels_1 + test_labels_2\n",
    "\n",
    "# Create a training dataset with HeadCT files\n",
    "train_ds = MedNISTDataset(train_files)\n",
    "trainloader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "# Create a validation dataset with HeadCT files\n",
    "val_ds = MedNISTDataset(val_files)\n",
    "valloader = DataLoader(val_ds, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "# Create a test dataset with HeadCT and Hand files\n",
    "test_ds = MedNISTTestDataset(test_files, test_labels)\n",
    "testloader = DataLoader(test_ds, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "print('Train dataset size:', len(train_ds))\n",
    "print('Batches in trainloader:', len(trainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e4dd2",
   "metadata": {},
   "source": [
    "### Show some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83270ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([img for img in next(iter(trainloader))[:10, 0]])\n",
    "plot([img for img in next(iter(valloader))[:10, 0]])\n",
    "imgs, labels = next(iter(testloader))\n",
    "plot([img for img in imgs[:10, 0]], titles=labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a58c39f",
   "metadata": {},
   "source": [
    "## Create an Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed63a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.latent_dim = 128\n",
    "ae = Autoencoder(latent_dim=config.latent_dim)\n",
    "print(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_train_step(ae, x, optimizer, device):\n",
    "    ae.train()\n",
    "    optimizer.zero_grad()\n",
    "    x = x.to(device)\n",
    "    x_recon = ae(x)\n",
    "    loss = ae.loss_function(x, x_recon)  # MSE loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def ae_val_step(ae, x, device):\n",
    "    ae.eval()\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        x_recon = ae(x)\n",
    "    return ae.loss_function(x, x_recon).item(), x_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9661eb",
   "metadata": {},
   "outputs": [],
   "source": [
    " def train_ae(config, ae, optimizer, trainloader, valloader):\n",
    "    i_step = 0\n",
    "    i_epoch = 0\n",
    "    all_losses = []\n",
    "    losses = []\n",
    "    ae.train()\n",
    "    while True:\n",
    "        for x in trainloader:\n",
    "            # Train step\n",
    "            loss = ae_train_step(ae, x, optimizer, config.device)\n",
    "\n",
    "            # Store metrics\n",
    "            losses.append(loss)\n",
    "            all_losses.append(loss)\n",
    "\n",
    "            # Log\n",
    "            if i_step % config.log_frequency == 0:\n",
    "                print(f'Iteration {i_step} - train loss {np.mean(losses):.4f}')\n",
    "                losses = []\n",
    "\n",
    "            # Validate\n",
    "            if i_step % config.val_frequency == 0:\n",
    "                val_loss, x_val, x_recon = validate_ae(config, ae, valloader)\n",
    "                print(f'Iteration {i_step} - val loss {val_loss:.4f}')\n",
    "                residual = torch.abs(x_val - x_recon)\n",
    "                plot([x_val[0, 0], x_recon[0, 0], residual[0, 0]],\n",
    "                     titles=['input', 'reconstruction', 'residual'])\n",
    "\n",
    "            # Finish\n",
    "            i_step += 1\n",
    "            if i_step >= config.num_steps:\n",
    "                print('Finished training')\n",
    "                return\n",
    "        i_epoch += 1\n",
    "        print(f'Finished epoch {i_epoch}')\n",
    "\n",
    "\n",
    "def validate_ae(config, ae, valloader):\n",
    "    losses = []\n",
    "    for x in valloader:\n",
    "        loss, x_recon = ae_val_step(ae, x, config.device)\n",
    "        losses.append(loss)\n",
    "    return np.mean(losses), x.cpu(), x_recon.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f361171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train config\n",
    "config.lr = 1e-3\n",
    "config.num_steps = 1000\n",
    "config.log_frequency = 10\n",
    "config.val_frequency = 100\n",
    "\n",
    "# Re-initialize Autoencoder\n",
    "ae = Autoencoder(latent_dim=config.latent_dim).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(ae.parameters(), lr=config.lr)\n",
    "\n",
    "# Train\n",
    "print('Start training...')\n",
    "train_ae(config, ae, optimizer, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a26c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "def ae_test_step(ae, x, device):\n",
    "    ae.eval()\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        x_recon = ae(x)\n",
    "    return x, x_recon, torch.abs(x - x_recon)\n",
    "\n",
    "def test_ae(config, ae, testloader):\n",
    "    scores = []\n",
    "    labels = []\n",
    "    ae.eval()\n",
    "    for x, y in testloader:\n",
    "        x, x_recon, residual = ae_test_step(ae, x, config.device)\n",
    "        anomaly_score = torch.mean(residual, dim=(1, 2, 3))\n",
    "        scores.extend(anomaly_score.cpu().numpy())\n",
    "        labels.extend(y.numpy())\n",
    "\n",
    "    return scores, labels\n",
    "\n",
    "scores, labels = test_ae(config, ae, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics import roc_auc_score  # Only quick test, remove later\n",
    "auroc = roc_auc_score(labels, scores)\n",
    "print(auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc2dc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
